{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvpY_Ms5iEeh"
      },
      "source": [
        "This AI builder supports two algorithms:\n",
        "\n",
        "\n",
        "*   LinearRegressor - Predicting range of values [Continuous data]\n",
        "*   LinearClassifier - Predicting true or false [Discrete data]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your data's output is Zeros and Ones, then your data will be detected as Discrete.\n",
        "\n",
        "If your data output contains more than 2 values then your data will be detected as continuous"
      ],
      "metadata": {
        "id": "saLGYJdXmIT0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gY4lC5svQKW_",
        "outputId": "c74f04bf-fec8-4ed8-d4f0-34a060addc59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This cell has nothing to do with the program, it is just required to initiate the runtime\n"
          ]
        }
      ],
      "source": [
        "print(f\"This cell has nothing to do with the program, it is just required to initiate the runtime\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t07RyIBJO9rk"
      },
      "source": [
        "# **Importing Data**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "To import data follow these steps:\n",
        "\n",
        "**NOTICE:** Run the codeblock above before starting these instructions or then it won't let you import the data, because it can't find a runtime\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "1) Run the code block above\n",
        "\n",
        "2) Download the data you want to use through websites, make sure to have a brief understanding of the data\n",
        "\n",
        "3) Click the 4th button at the right of your screen (Should look like a rectangle or folder)\n",
        "\n",
        "4) When a pop up page opens at the left of your screen, click on the button that shows a paper with an arrow pointing up\n",
        "\n",
        "5) Locate the Data file for both the testing and training\n",
        "\n",
        "6) Make sure it shows you the 2 data folders are in the document, if it doesn't show check if there is a white circle at the bottom of the pop up page, if there is wait a little bit until it loads\n",
        "\n",
        "7) Follow the instructions underneath\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Reminder:** The runtime will disconnect if it detects you inactive. Click reconnect to ignore this message and continue using the AI, if it doesn't work repeat these 7 steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unPa7y2EDyd4"
      },
      "source": [
        "# **Instructions:**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Before starting any of these instructions read the message above to import your data then kindly follow these instructions.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "1) Click on the runtime button at the top of your screen and click \"Run all\"\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "2) I suggest you don't move around the screen so when the program requires input, it takes you to the input boxes\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "3) **Important:** When you are asked to input what column the AI needs to predict, go to your dataset provider and search for which column you are expecting as an answer. This is the column the AI needs to use to train, if you do not input the correct column i guarantee the AI will have 0% accuracy\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "4) When it shows you column options -- Choose which columns you want the AI to train on\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "5) When it asks you for cleaning data -- I suggest you choose automatic, but if you choose manual some errors may pop up with you inputing text when numbers are expected and vise versa\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "6) If you wish to replace a value in the dataset, you can use the replace code block before training the AI. If you are not in need of replacing a value, enter (N) when the program asks [Do you want to replace any values?]\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "7) When asked if you wish to enter select the algorithm manually or automatically. I suggest you choose automatically. Unless you wish to experiment with the program or your data was wrongly classified as discrete or continuous, please use automatically.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "8) The AI will automatically train. If you have provided testing data, the AI will output its prediction and a graph will display these predictions. If you chose to enter information in the user input section, the AI will predict depending on the information you have given it and the program will display a graph based on the AI's prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiKfomRMUjWI"
      },
      "outputs": [],
      "source": [
        "!pip install -q sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTwEpUgkUnd1"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8BlkroyUnwG"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib\n",
        "\n",
        "import tensorflow.compat.v2.feature_column as fc\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plu5j5P8yGin"
      },
      "source": [
        "Make sure your training dataset excel file is named **(train)**.\n",
        "\n",
        "Testing dataset is optional, however if you inset a testing dataset please name the excel file **(test)**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LyDouD9P2e8"
      },
      "outputs": [],
      "source": [
        "#Loading in Dataset\n",
        "\n",
        "dftrain = pd.read_csv('train.csv')\n",
        "\n",
        "try:\n",
        "  dfeval = pd.read_csv('test.csv')\n",
        "  selection = '2'\n",
        "\n",
        "except:\n",
        "  print(\"Testing data not detected!\")\n",
        "  selection = '1'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McJaLKSiHLFI"
      },
      "outputs": [],
      "source": [
        "print(\"Make sure it is written properly if there is a capital at the beggining, include it\")\n",
        "print(\"\")\n",
        "print(f\"Column list: {dftrain.columns}\")\n",
        "print(\"\")\n",
        "Wanted_Prediction_Column = input(f\"Input the name of the column that the AI needs to predict \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QK2_1WZ7zRP"
      },
      "outputs": [],
      "source": [
        "Column_Options = dftrain.columns\n",
        "\n",
        "Cat_Col_Opt = []\n",
        "Num_Col_Opt = []\n",
        "\n",
        "\n",
        "#Classifying columns\n",
        "\n",
        "for col in Column_Options:\n",
        "    if dftrain[col].dtype == 'object':\n",
        "        Cat_Col_Opt.append(col)\n",
        "    else:\n",
        "        Num_Col_Opt.append(col)\n",
        "\n",
        "\n",
        "#Removing unwanted response from option list\n",
        "try:\n",
        "  Num_Col_Opt.remove(Wanted_Prediction_Column)\n",
        "\n",
        "except:\n",
        "  Cat_Col_Opt.remove(Wanted_Prediction_Column)\n",
        "\n",
        "\n",
        "#Letting the user pick the columns\n",
        "CATEGORICAL_COLUMNS = []\n",
        "NUMERIC_COLUMNS = []\n",
        "\n",
        "while True:\n",
        "    print(f\"Column options: {Cat_Col_Opt}\")\n",
        "    print(\"Type !All to use all the data\")\n",
        "    user_input1 = input(\"Enter Catagoric Name of column's (!Finish to stop): \")\n",
        "    if user_input1 == \"!Finish\":\n",
        "        break\n",
        "\n",
        "    if user_input1 == \"!All\":\n",
        "        CATEGORICAL_COLUMNS = Cat_Col_Opt\n",
        "        #Cat_Col_Opt = []\n",
        "        break\n",
        "\n",
        "    if user_input1 == Wanted_Prediction_Column:\n",
        "      continue\n",
        "    CATEGORICAL_COLUMNS.append(user_input1)\n",
        "    Cat_Col_Opt.remove(user_input1)\n",
        "\n",
        "\n",
        "while True:\n",
        "    print(f\"Column options: {Num_Col_Opt}\")\n",
        "    print(\"Type !All to use all the data\")\n",
        "    user_input2 = input(\"Enter Numeric Name of column's (!Finish to stop): \")\n",
        "    if user_input2 == \"!Finish\":\n",
        "        break\n",
        "\n",
        "    if user_input2 == \"!All\":\n",
        "        NUMERIC_COLUMNS = Num_Col_Opt\n",
        "        #Num_Col_Opt = []\n",
        "        break\n",
        "\n",
        "    if user_input2 == Wanted_Prediction_Column:\n",
        "        continue\n",
        "    NUMERIC_COLUMNS.append(user_input2)\n",
        "    Num_Col_Opt.remove(user_input2)\n",
        "\n",
        "#Calculate unused options\n",
        "Left = []\n",
        "\n",
        "#Checks if Categorical column and Numeric had !All inputed in it\n",
        "if user_input1 != '!All':\n",
        "  for i in Cat_Col_Opt:\n",
        "    Left.append(i)\n",
        "\n",
        "if user_input2 != '!All':\n",
        "  for i in Num_Col_Opt:\n",
        "    Left.append(i)\n",
        "\n",
        "#Dropping unused columns\n",
        "for i in Left:\n",
        "  if i == Wanted_Prediction_Column:\n",
        "    pass\n",
        "\n",
        "  else:\n",
        "    dftrain.drop([i], axis=1, inplace=True)\n",
        "    if selection == '2':\n",
        "      dfeval.drop([i], axis=1, inplace=True)\n",
        "\n",
        "#Outputing options\n",
        "print(\"------------------------------------------------------------------------------------------------\")\n",
        "print(f\"Unused Columns: {Left}\")\n",
        "print(\"CATEGORICAL_COLUMNS:\", CATEGORICAL_COLUMNS)\n",
        "print(\"NUMERIC_COLUMNS:\", NUMERIC_COLUMNS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98Pre-cCTNdD"
      },
      "outputs": [],
      "source": [
        "print(\"----------------------------------------------------------------------\")\n",
        "print(\"\")\n",
        "print(dftrain.isna().sum())\n",
        "try:\n",
        "  print(\"\")\n",
        "  print(dfeval.isna().sum())\n",
        "  print(\"----------------------------------------------------------------------\")\n",
        "\n",
        "except:\n",
        "  pass\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "if selection == '2':\n",
        "  print(f\"A for Automatic cleaning\")\n",
        "  print(f\"M for manual cleaning\")\n",
        "  option = input()\n",
        "\n",
        "  print(\"\")\n",
        "\n",
        "  print(f\"!Copy to duplicate cleaning to both datasets\")\n",
        "  print(f\"!Set to clean datasets manually\")\n",
        "  option2 = input()\n",
        "\n",
        "  #If user wants to fill evaluation dataframe with same values than testing dataframe\n",
        "  if option2 == '!Copy':\n",
        "    while True:\n",
        "      if option == 'A':\n",
        "        print(f\"Fixing...\")\n",
        "        dftrain.dropna(inplace=True)\n",
        "        dfeval.dropna(inplace=True)\n",
        "        dftrain = dftrain.reset_index(drop=True)\n",
        "        dfeval = dfeval.reset_index(drop=True)\n",
        "        break\n",
        "\n",
        "      elif option == 'M':\n",
        "        print(f\"Manual fix activated\")\n",
        "        print(\"----------------------------------------------------------------------\")\n",
        "        print(\"\")\n",
        "        print(dftrain.isna().sum())\n",
        "        print(\"\")\n",
        "        print(dfeval.isna().sum())\n",
        "        print(\"----------------------------------------------------------------------\")\n",
        "        print(\"\")\n",
        "\n",
        "        #Training\n",
        "        print(f\"Training data fix\")\n",
        "        print(\"Enter !Drop to drop NaN\")\n",
        "\n",
        "        print(\"Non-Numeric dataset\")\n",
        "        for cat in CATEGORICAL_COLUMNS:\n",
        "          fix = input(f\"Enter filling for NaN in {cat} \")\n",
        "\n",
        "          if fix == '!Drop':\n",
        "            dftrain.dropna(subset=[cat], inplace=True)\n",
        "            dftrain = dftrain.reset_index(drop=True)\n",
        "            dfeval.dropna(subset=[cat], inplace=True)\n",
        "            dfeval = dftrain.reset_index(drop=True)\n",
        "\n",
        "          else:\n",
        "            dftrain[cat].fillna(fix, inplace=True)\n",
        "            dfeval[cat].fillna(fix, inplace=True)\n",
        "\n",
        "        print(\"Numeric dataset\")\n",
        "        for num in NUMERIC_COLUMNS:\n",
        "          fix = input(f\"Enter filling for NaN in {num} \")\n",
        "\n",
        "          if fix == '!Drop':\n",
        "            dftrain.dropna(subset=[num], inplace=True)\n",
        "            dftrain = dftrain.reset_index(drop=True)\n",
        "            dfeval.dropna(subset=[num], inplace=True)\n",
        "            dfeval = dftrain.reset_index(drop=True)\n",
        "\n",
        "          else:\n",
        "            dftrain[num].fillna(int(fix), inplace=True)\n",
        "            dfeval[num].fillna(int(fix), inplace=True)\n",
        "\n",
        "        break\n",
        "\n",
        "  #If user wants to fill evaluation dataframe with different values than testing dataframe\n",
        "  if option2 == '!Set':\n",
        "    while True:\n",
        "      if option == 'A':\n",
        "        print(f\"Fixing...\")\n",
        "        dftrain.dropna(inplace=True)\n",
        "        dfeval.dropna(inplace=True)\n",
        "        dftrain = dftrain.reset_index(drop=True)\n",
        "        dfeval = dfeval.reset_index(drop=True)\n",
        "        break\n",
        "\n",
        "      elif option == 'M':\n",
        "        print(f\"Manual fix activated\")\n",
        "        print(\"----------------------------------------------------------------------\")\n",
        "        print(\"\")\n",
        "        print(dftrain.isna().sum())\n",
        "        print(\"\")\n",
        "        print(dfeval.isna().sum())\n",
        "        print(\"----------------------------------------------------------------------\")\n",
        "        print(\"\")\n",
        "\n",
        "        #Training\n",
        "        print(f\"Training data fix\")\n",
        "        print(\"Enter !Drop to drop NaN\")\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Non-Numeric dataset\")\n",
        "        for cat in CATEGORICAL_COLUMNS:\n",
        "          fix = input(f\"Enter filling for NaN in {cat} \")\n",
        "\n",
        "          if fix == '!Drop':\n",
        "            dftrain.dropna(subset=[cat], inplace=True)\n",
        "            dftrain = dftrain.reset_index(drop=True)\n",
        "\n",
        "          else:\n",
        "            dftrain[cat].fillna(fix, inplace=True)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Numeric dataset\")\n",
        "        for num in NUMERIC_COLUMNS:\n",
        "          fix = input(f\"Enter filling for NaN in {num} \")\n",
        "\n",
        "          if fix == '!Drop':\n",
        "            dftrain.dropna(subset=[num], inplace=True)\n",
        "            dftrain = dftrain.reset_index(drop=True)\n",
        "\n",
        "          else:\n",
        "            dftrain[num].fillna(int(fix), inplace=True)\n",
        "\n",
        "\n",
        "        #Testing\n",
        "        print(f\"Testing data fix\")\n",
        "        print(\"Enter !Drop to drop NaN\")\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Non-Numeric dataset\")\n",
        "        for cat in CATEGORICAL_COLUMNS:\n",
        "          fix = input(f\"Enter filling for NaN in {cat} \")\n",
        "\n",
        "          if fix == '!Drop':\n",
        "            dfeval.dropna(subset=[cat], inplace=True)\n",
        "            dfeval = dfeval.reset_index(drop=True)\n",
        "\n",
        "          else:\n",
        "            dfeval[cat].fillna(fix, inplace=True)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Numeric dataset\")\n",
        "        for num in NUMERIC_COLUMNS:\n",
        "          fix = input(f\"Enter filling for NaN in {num} \")\n",
        "\n",
        "          if fix == '!Drop':\n",
        "            dfeval.dropna(subset=[num], inplace=True)\n",
        "            dfeval = dfeval.reset_index(drop=True)\n",
        "\n",
        "          else:\n",
        "            dfeval[num].fillna(int(fix), inplace=True)\n",
        "\n",
        "        break\n",
        "\n",
        "#Training data only cleaning system\n",
        "if selection == '1':\n",
        "  print(f\"A for Automatic cleaning\")\n",
        "  print(f\"M for manual cleaning\")\n",
        "  option = input()\n",
        "\n",
        "  print(\"\")\n",
        "\n",
        "  #If user wants to fill evaluation dataframe with same values than testing dataframe\n",
        "if option == 'A':\n",
        "  print(f\"Fixing...\")\n",
        "  dftrain.dropna(inplace=True)\n",
        "  dftrain = dftrain.reset_index(drop=True)\n",
        "\n",
        "elif option == 'M':\n",
        "  print(f\"Manual fix activated\")\n",
        "  print(\"----------------------------------------------------------------------\")\n",
        "  print(\"\")\n",
        "  print(dftrain.isna().sum())\n",
        "  print(\"----------------------------------------------------------------------\")\n",
        "  print(\"\")\n",
        "\n",
        "  #Training\n",
        "  print(f\"Training data fix\")\n",
        "  print(\"Enter !Drop to drop NaN\")\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Non-Numeric dataset\")\n",
        "  for cat in CATEGORICAL_COLUMNS:\n",
        "    fix = input(f\"Enter filling for NaN in {cat} \")\n",
        "\n",
        "    if fix == '!Drop':\n",
        "      dftrain.dropna(subset=[cat], inplace=True)\n",
        "      dftrain = dftrain.reset_index(drop=True)\n",
        "\n",
        "    else:\n",
        "      dftrain[cat].fillna(fix, inplace=True)\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Numeric dataset\")\n",
        "  for num in NUMERIC_COLUMNS:\n",
        "    fix = input(f\"Enter filling for NaN in {num} \")\n",
        "\n",
        "    if fix == '!Drop':\n",
        "      dftrain.dropna(subset=[num], inplace=True)\n",
        "      dftrain = dftrain.reset_index(drop=True)\n",
        "\n",
        "    else:\n",
        "      dftrain[num].fillna(int(fix), inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjB42ZLnNSFY"
      },
      "outputs": [],
      "source": [
        "#Replace system\n",
        "print(f\"Cannot switch column type between numerical or categorical\")\n",
        "\n",
        "while True:\n",
        "  print(\"Do you want to replace any values?\")\n",
        "  r_input = input(f\"Y|N \")\n",
        "\n",
        "  if r_input == 'N':\n",
        "    break\n",
        "\n",
        "  elif r_input == 'Y':\n",
        "\n",
        "    print(\"Type !Finish to stop\")\n",
        "    column_list = []\n",
        "    for i in dftrain.columns:\n",
        "      if i == Wanted_Prediction_Column:\n",
        "        continue\n",
        "      column_list.append(i)\n",
        "\n",
        "    while True:\n",
        "      print(column_list)\n",
        "      print(\"--------------------------------------------------------------------------------\")\n",
        "      r_column = input(\"Enter the name of the column you want to edit \")\n",
        "\n",
        "      if r_column == '!Finish':\n",
        "        break\n",
        "\n",
        "      if r_column == Wanted_Prediction_Column:\n",
        "        continue\n",
        "\n",
        "      unique_values = dftrain[r_column].unique()\n",
        "      print(unique_values)\n",
        "\n",
        "      r_val = input(\"Enter value you want to replace \")\n",
        "      if r_val == '!Finish':\n",
        "        break\n",
        "\n",
        "      new_val = input(\"Enter the value you want to replace with \")\n",
        "      if new_val == '!Finish':\n",
        "        break\n",
        "\n",
        "\n",
        "      if selection == '2':\n",
        "        dftrain[r_column].replace(r_val, new_val, inplace=True)\n",
        "        dfeval[r_column].replace(r_val, new_val, inplace=True)\n",
        "\n",
        "      if selection == '1':\n",
        "        dftrain[r_column].replace(r_val, new_val, inplace=True)\n",
        "\n",
        "    break\n",
        "\n",
        "  else:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upGgIvdH_sXq"
      },
      "outputs": [],
      "source": [
        "y_train = dftrain.pop(Wanted_Prediction_Column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQHyvaW9ecHU"
      },
      "outputs": [],
      "source": [
        "feature_columns = []\n",
        "for feature_name in CATEGORICAL_COLUMNS:\n",
        "  vocabulary = dftrain[feature_name].unique()\n",
        "  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
        "\n",
        "for feature_name in NUMERIC_COLUMNS:\n",
        "  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
        "\n",
        "print(feature_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyqTJ7ZzgfV3"
      },
      "outputs": [],
      "source": [
        "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
        "  def input_function():\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(1000)\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    return ds\n",
        "  return input_function\n",
        "\n",
        "train_input_fn = make_input_fn(dftrain, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axKqEYqmgm8n"
      },
      "outputs": [],
      "source": [
        "print(f\"Do you want to enter data type for the target column manually?\")\n",
        "day = input(f\"[Y | N] \")\n",
        "\n",
        "while True:\n",
        "\n",
        "  if day == 'N':\n",
        "    if len(y_train.unique()) > 2:\n",
        "      print(\"\")\n",
        "      print(\"--------------------------------------------------------------------------------------\")\n",
        "      print(f\"Detected {Wanted_Prediction_Column} as continuous\")\n",
        "      print(\"\")\n",
        "      linear_est = tf.estimator.LinearRegressor(feature_columns=feature_columns)\n",
        "      print(\"Linear Regressor algorithm used\")\n",
        "      break\n",
        "\n",
        "    elif len(y_train.unique()) == 2:\n",
        "      print(\"\")\n",
        "      print(\"--------------------------------------------------------------------------------------\")\n",
        "      print(f\"Detected {Wanted_Prediction_Column} as discrete\")\n",
        "      print(\"\")\n",
        "      linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
        "      print(\"Linear Classifier algorithm used\")\n",
        "      break\n",
        "\n",
        "  elif day == 'Y':\n",
        "    alg = input(f\"Is the target column continuous or discrete? [D | C] \")\n",
        "\n",
        "    if alg == 'D':\n",
        "      linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
        "      print(\"Linear Classifier algorithm used\")\n",
        "      break\n",
        "\n",
        "    elif alg == 'C':\n",
        "      linear_est = tf.estimator.LinearRegressor(feature_columns=feature_columns)\n",
        "      print(\"Linear Regressor algorithm used\")\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFzvwaA7gqsJ"
      },
      "outputs": [],
      "source": [
        "linear_est.train(train_input_fn)  # train\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEL0drQ_qfZu"
      },
      "outputs": [],
      "source": [
        "if selection == '2':\n",
        "  def make_input_fn(data, num_epochs=1, shuffle=False, batch_size=32):\n",
        "      def input_fn():\n",
        "          dataset = tf.data.Dataset.from_tensor_slices(dict(data))\n",
        "          if shuffle:\n",
        "              dataset = dataset.shuffle(buffer_size=len(data))\n",
        "          dataset = dataset.batch(batch_size)\n",
        "          dataset = dataset.repeat(num_epochs)\n",
        "          return dataset\n",
        "      return input_fn\n",
        "\n",
        "  eval_input_fn = make_input_fn(dfeval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgdUvy8wpxKW"
      },
      "outputs": [],
      "source": [
        "if selection == '2':\n",
        "  prediction = list(linear_est.predict(eval_input_fn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhrP4cNqKWnj"
      },
      "outputs": [],
      "source": [
        "if selection == '2':\n",
        "  Guess_list = []\n",
        "  for pred in prediction:\n",
        "    Guess_list.append(pred['class_ids'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mf4OjEVCzl9Y"
      },
      "outputs": [],
      "source": [
        "if selection == '2':\n",
        "  print(Guess_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xkkp0l9OF54S"
      },
      "outputs": [],
      "source": [
        "if selection == '2':\n",
        "  Output_Eval = []\n",
        "\n",
        "  for i in Guess_list:\n",
        "    if i == 0:\n",
        "      Output_Eval.append(\"False\")\n",
        "\n",
        "    elif i == 1:\n",
        "      Output_Eval.append(\"True\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cx46O65mHF8a"
      },
      "outputs": [],
      "source": [
        "if selection == '2':\n",
        "  print(Output_Eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXe81KmrHRS-"
      },
      "source": [
        "# **Predicting user input dataframe**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "The following section allows you to input data in the columns you selected and then it'll give you a prediciton."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy1dKopOKgiC"
      },
      "source": [
        "# **Instructions:**\n",
        "\n",
        "\n",
        "\n",
        "*   Run the code blocks below\n",
        "*   Input the information for the columns you picked previously\n",
        "*   When done entering for the first column type !Finish\n",
        "*   Keep typing information for the other columns, you don't need to write !Finish for the other columns but they must have the same amount of items as the first column\n",
        "*   When you finish putting in all the data, the AI will give you a prediction\n",
        "\n",
        "\n",
        "Note: Empty spaces will lead to an error and so will entering letters when numbers is required.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ShkctblE8Dr"
      },
      "outputs": [],
      "source": [
        "\n",
        "# define the columns you want to use\n",
        "cols = dftrain.columns.tolist()\n",
        "\n",
        "# create an empty DataFrame with those columns\n",
        "user_data = pd.DataFrame(columns=cols)\n",
        "\n",
        "Entry_c = 0\n",
        "\n",
        "# loop over the columns and ask the user for input\n",
        "for col in cols:\n",
        "\n",
        "    #Checks if the loop has picked the first column name\n",
        "    if col == cols[0]:\n",
        "\n",
        "      column_data = []\n",
        "      print(\"\")\n",
        "      print(f\"Enter values for {col}, or type !Finish to submit.\")\n",
        "      print(f\"Example values ({dftrain[col].unique()})\")\n",
        "      while True:\n",
        "          value = input(f\"{col}: \")\n",
        "          if value == '!Finish':\n",
        "              print(\"You must input the same amount of entries as the initial column\")\n",
        "              break\n",
        "\n",
        "          try:\n",
        "            # try to convert input to a float or integer\n",
        "            value = int(value)\n",
        "          except ValueError:\n",
        "              try:\n",
        "                  value = float(value)\n",
        "              except ValueError:\n",
        "                  pass\n",
        "\n",
        "          column_data.append(value)\n",
        "          Entry_c += 1\n",
        "\n",
        "\n",
        "      # add the column data to the user_data DataFrame\n",
        "      for i in range(len(column_data)):\n",
        "          if i >= len(user_data):\n",
        "              user_data.loc[i] = ''\n",
        "          user_data.loc[i, col] = column_data[i]\n",
        "\n",
        "    else:\n",
        "\n",
        "      column_data = []\n",
        "      print(\"\")\n",
        "      print(f\"Enter values for {col}\")\n",
        "      print(f\"Example values ({dftrain[col].unique()})\")\n",
        "      for i in range(Entry_c):\n",
        "          value = input(f\"{col}: \")\n",
        "\n",
        "          try:\n",
        "            # try to convert input to a float or integer\n",
        "            value = int(value)\n",
        "          except ValueError:\n",
        "              try:\n",
        "                  value = float(value)\n",
        "              except ValueError:\n",
        "                  pass\n",
        "\n",
        "          column_data.append(value)\n",
        "\n",
        "\n",
        "      # add the column data to the user_data DataFrame\n",
        "      for i in range(len(column_data)):\n",
        "          if i >= len(user_data):\n",
        "              user_data.loc[i] = ''\n",
        "          user_data.loc[i, col] = column_data[i]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rl0u2SnV78Jf"
      },
      "outputs": [],
      "source": [
        "def predict_dataframe(dataframe, model):\n",
        "    # Convert the dataframe to a dictionary\n",
        "    data_dict = dataframe.to_dict(orient='list')\n",
        "\n",
        "    # Create an input function to feed the data to the model\n",
        "    def input_fn():\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(dict(data_dict))\n",
        "        dataset = dataset.batch(len(dataframe))\n",
        "        return dataset\n",
        "\n",
        "    # Make predictions using the input function and the provided model\n",
        "    predictions = list(model.predict(input_fn))\n",
        "\n",
        "    # Extract the predicted values from the output dictionary\n",
        "    predicted_values = []\n",
        "    for prediction in predictions:\n",
        "        if 'class_ids' in prediction:\n",
        "            predicted_values.append(prediction['class_ids'][0])\n",
        "        elif 'predictions' in prediction:\n",
        "            predicted_values.append(prediction['predictions'][0])\n",
        "        # Add more conditions if needed for different prediction structures\n",
        "\n",
        "    return predicted_values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RU_AqrJX4li"
      },
      "outputs": [],
      "source": [
        "predictions = predict_dataframe(user_data, linear_est)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iwQIanTd6TP"
      },
      "outputs": [],
      "source": [
        "if len(y_train.unique()) == 2:\n",
        "  Output_User = []\n",
        "\n",
        "  for i in predictions:\n",
        "    if i == 0:\n",
        "      Output_User.append(\"False\")\n",
        "\n",
        "    elif i == 1:\n",
        "      Output_User.append(\"True\")\n",
        "\n",
        "  print(Output_User)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGuJ4ePSeubm"
      },
      "outputs": [],
      "source": [
        "if len(y_train.unique()) > 2:\n",
        "  print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Graph**"
      ],
      "metadata": {
        "id": "Cxa8aU9gWKT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training data graph"
      ],
      "metadata": {
        "id": "lFHNcTA8Go2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For continuous data\n",
        "if len(y_train.unique()) > 2:\n",
        "  value_counts = y_train.value_counts().to_dict()\n",
        "\n",
        "  labels = list(value_counts.keys())\n",
        "  data = list(value_counts.values())\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.bar(labels, data, width=2)\n",
        "\n",
        "  ax.set_title('Column Graph')\n",
        "  ax.set_xlabel(Wanted_Prediction_Column)\n",
        "  ax.set_ylabel('Frequency')\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  sorted_dict = dict(sorted(value_counts.items()))\n",
        "  print(sorted_dict)\n",
        "\n",
        "#For discrete data\n",
        "else:\n",
        "  value_counts = y_train.value_counts().to_dict()\n",
        "\n",
        "  labels = list(value_counts.keys())\n",
        "  data = list(value_counts.values())\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.bar(labels, data, width=0.5)\n",
        "\n",
        "  ax.set_title('Column Graph')\n",
        "  ax.set_xlabel(Wanted_Prediction_Column)\n",
        "  ax.set_ylabel('Frequency')\n",
        "\n",
        "  plt.xticks(sorted(labels))\n",
        "  plt.show()\n",
        "\n",
        "  sorted_dict = dict(sorted(value_counts.items()))\n",
        "  print(sorted_dict)"
      ],
      "metadata": {
        "id": "YoOYP0W2EmxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing data graph\n",
        "\n",
        "Answer provided by AI prediction"
      ],
      "metadata": {
        "id": "cZYya4SyGxbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if selection == '2':\n",
        "  dfeval[Wanted_Prediction_Column] = Guess_list\n",
        "  value_counts = dfeval[Wanted_Prediction_Column].value_counts().to_dict()\n",
        "\n",
        "  labels = list(value_counts.keys())\n",
        "  data = list(value_counts.values())\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.bar(labels, data, width=0.5)\n",
        "\n",
        "  ax.set_title('Column Graph')\n",
        "  ax.set_xlabel(Wanted_Prediction_Column)\n",
        "  ax.set_ylabel('Frequency')\n",
        "\n",
        "\n",
        "  plt.xticks(sorted(labels))\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  sorted_dict = dict(sorted(value_counts.items()))\n",
        "  print(sorted_dict)"
      ],
      "metadata": {
        "id": "dFEdMAmTqwza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User input graph\n",
        "\n",
        "Display of the predictions that the AI predicted when viewing user input"
      ],
      "metadata": {
        "id": "hcUxSKoyG66I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For continuous data\n",
        "if len(y_train.unique()) > 2:\n",
        "  user_data[Wanted_Prediction_Column] = predictions\n",
        "\n",
        "  value_counts = user_data[Wanted_Prediction_Column].value_counts().to_dict()\n",
        "\n",
        "  labels = list(value_counts.keys())\n",
        "  data = list(value_counts.values())\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.bar(labels, data, width=0.5)\n",
        "\n",
        "  ax.set_title('Column Graph')\n",
        "  ax.set_xlabel(Wanted_Prediction_Column)\n",
        "  ax.set_ylabel('Frequency')\n",
        "\n",
        "  highest_value = int(max(labels))\n",
        "\n",
        "  tick_l = []\n",
        "  for i in range(highest_value+2):\n",
        "    if i % 2 == 0:\n",
        "      tick_l.append(i)\n",
        "\n",
        "  plt.xticks(tick_l)\n",
        "\n",
        "\n",
        "  #Legend\n",
        "  sorted_dict = dict(sorted(value_counts.items()))\n",
        "  sorted_labels = list(sorted_dict.keys())\n",
        "  sorted_data = list(sorted_dict.values())\n",
        "\n",
        "  legend_labels = [f'data_class={val}, freq={freq}' for val, freq in zip(sorted_labels, sorted_data)]\n",
        "  for i, label in enumerate(legend_labels):\n",
        "      plt.text(1.05, i*0.1, label, transform=plt.gca().transAxes)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  print(sorted_dict)\n",
        "\n",
        "#For discrete data\n",
        "else:\n",
        "  user_data[Wanted_Prediction_Column] = predictions\n",
        "\n",
        "  value_counts = user_data[Wanted_Prediction_Column].value_counts().to_dict()\n",
        "\n",
        "  labels = list(value_counts.keys())\n",
        "  data = list(value_counts.values())\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.bar(labels, data, width=0.5)\n",
        "\n",
        "  ax.set_title('Column Graph')\n",
        "  ax.set_xlabel(Wanted_Prediction_Column)\n",
        "  ax.set_ylabel('Frequency')\n",
        "\n",
        "  plt.xticks(sorted(labels))\n",
        "\n",
        "  #Legend\n",
        "  sorted_dict = dict(sorted(value_counts.items()))\n",
        "  sorted_labels = list(sorted_dict.keys())\n",
        "  sorted_data = list(sorted_dict.values())\n",
        "\n",
        "  legend_labels = [f'data_class={val}, freq={freq}' for val, freq in zip(sorted_labels, sorted_data)]\n",
        "  for i, label in enumerate(legend_labels):\n",
        "      plt.text(1.05, i*0.1, label, transform=plt.gca().transAxes)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  print(sorted_dict)"
      ],
      "metadata": {
        "id": "xDlGBZ8-rbBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Statistics**"
      ],
      "metadata": {
        "id": "U_EbiNIjWS6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.describe()"
      ],
      "metadata": {
        "id": "_tCY7aoWIV1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Range: {y_train.describe()[7]-y_train.describe()[3]}\")\n",
        "print(f\"IQR: {y_train.describe()[6]-y_train.describe()[4]}\")"
      ],
      "metadata": {
        "id": "OUJ1d499Jeia"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}